{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lab material presented here is based on the data provided by the [OpenFlights](https://openflights.org/data.html) dataset that contains information on airports, airlines and routes.\n",
    "\n",
    "The [OpenFlights](https://openflights.org/data.html) dataset contains the ''Airport database'' that provides information for over 10,000 airports, train stations and ferry terminals spanning the globe. Each entry contains the following information:\n",
    "* **Airport ID** - Unique OpenFlights identifier for this airport.\n",
    "* **Name** - Name of airport. May or may not contain the City name.\n",
    "* **City** - Main city served by airport. May be spelled differently from Name.\n",
    "* **Country** - Country or territory where airport is located. See countries.dat to cross-reference to ISO 3166-1 codes.\n",
    "* **IATA** - 3-letter IATA code. Null if not assigned/unknown.\n",
    "* **ICAO** - 4-letter ICAO code. Null if not assigned.\n",
    "* **Latitude** - Decimal degrees, usually to six significant digits. Negative is South, positive is North.\n",
    "* **Longitude** - Decimal degrees, usually to six significant digits. Negative is West, positive is East.\n",
    "* **Altitude** - In feet.\n",
    "* **Timezone** - Hours offset from UTC. Fractional hours are expressed as decimals, eg. India is 5.5.\n",
    "* **DST** - Daylight savings time. One of E (Europe), A (US/Canada), S (South America), O (Australia), Z (New Zealand), N (None) or U (Unknown). See also: Help: Time\n",
    "* **Tz database time zone** - Timezone in \"tz\" (Olson) format, eg. \"America/Los_Angeles\".\n",
    "* **Type** - Type of the airport. Value \"airport\" for air terminals, \"station\" for train stations, \"port\" for ferry terminals and \"unknown\" if not known. In airports.csv, only type=airport is included.\n",
    "* **Source** - Source of this data. \"OurAirports\" for data sourced from OurAirports, \"Legacy\" for old data not matched to OurAirports (mostly DAFIF), \"User\" for unverified user contributions. In airports.csv, only source=OurAirports is included.\n",
    "\n",
    "The data is UTF-8 (Unicode) encoded.\n",
    "\n",
    "The [OpenFlights](https://openflights.org/data.html) dataset also contains the ''Route database'' which provides information for 59036 routes between 3209 airports on 531 airlines spanning the globe. Each entry contains the following information:\n",
    "* **Airline** - 2-letter (IATA) or 3-letter (ICAO) code of the airline.\n",
    "* **Airline ID** - Unique OpenFlights identifier for airline (see Airline).\n",
    "* **Source airport** - 3-letter (IATA) or 4-letter (ICAO) code of the source airport.\n",
    "* **Source airport ID** - Unique OpenFlights identifier for source airport (see Airport)\n",
    "* **Destination airport** - 3-letter (IATA) or 4-letter (ICAO) code of the destination airport.\n",
    "* **Destination airport ID** - Unique OpenFlights identifier for destination airport (see Airport)\n",
    "* **Codeshare** - \"Y\" if this flight is a codeshare (that is, not operated by Airline, but another carrier), empty otherwise.\n",
    "* **Stops** - Number of stops on this flight (\"0\" for direct)\n",
    "* **Equipment** - 3-letter codes for plane type(s) generally used on this flight, separated by spaces\n",
    "\n",
    "The data is ISO 8859-1 (Latin-1) encoded. The special value \\N is used for \"NULL\" to indicate that no value is available, and is understood automatically by MySQL if imported.\n",
    "\n",
    "## Airport dataset\n",
    "\n",
    "We start by retrieving the dataset directly from the web using [urllib](https://docs.python.org/3/library/urllib.html) method from the standard python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat'\n",
    "u = urllib.request.urlopen(url)\n",
    "rawdata = u.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the information retrieved to a local file so that we can work with the data without the need to re-download again and again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "localFile = open(\"airports.dat\", \"wb\")\n",
    "localFile.write(rawdata)\n",
    "localFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files retrieved follows a comma-separated format, so once again we use the [CSVREADER](https://docs.python.org/2/library/csv.html) a standard python package as explained in [Reading and writing comma-separated data](http://opentechschool.github.io/python-data-intro/core/csv.html). \n",
    "\n",
    "Notice that since the file is using [UTF-8 encoding](https://en.wikipedia.org/wiki/UTF-8) we need to specify this when using the _open_ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6874 airports. Encountered 310 errors\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "\n",
    "errors = 0\n",
    "f = open(\"airports.dat\", encoding='utf8')\n",
    "airports = []\n",
    "for row in csv.reader(f, delimiter=','):\n",
    "    thisLine = []\n",
    "    try:\n",
    "        thisLine.append(int(row[0])) # Airport ID\n",
    "        thisLine.append(row[1]) # Airport Name\n",
    "        thisLine.append(row[2]) # City\n",
    "        thisLine.append(row[3]) # Country\n",
    "        thisLine.append(row[4]) # IATA/FAA Code\n",
    "        thisLine.append(row[5]) # ICAO Code\n",
    "        thisLine.append(float(row[6])) # Latitude\n",
    "        thisLine.append(float(row[7])) # Longitude\n",
    "        thisLine.append(float(row[8])) # Altitude\n",
    "        thisLine.append(float(row[9])) # Timezone offset from UTC\n",
    "        thisLine.append(row[10]) # Daylight savings code\n",
    "        thisLine.append(row[11]) # Timezone\n",
    "        thisLine.append(row[12]) # Type\n",
    "        thisLine.append(row[13]) # Source\n",
    "\n",
    "    except :\n",
    "        errors += 1\n",
    "        \n",
    "    else:\n",
    "        airports.append(thisLine)\n",
    "        \n",
    "print(\"Loaded\", len(airports), \"airports. Encountered\", errors, \"errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routes dataset\n",
    "\n",
    "We will now proceed by downloading and parsing the routes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/jpatokal/openflights/master/data/routes.dat'\n",
    "u = urllib.request.urlopen(url)\n",
    "rawdata = u.read()\n",
    "localFile = open(\"routes.dat\", \"wb\")\n",
    "localFile.write(rawdata)\n",
    "localFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 66765 routes. Encountered 898 errors\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "f = open(\"routes.dat\")\n",
    "routes = []\n",
    "for row in csv.reader(f):\n",
    "    thisLine = []\n",
    "    try:\n",
    "        thisLine.append(row[0]) # IATA code\n",
    "        thisLine.append(int(row[1])) # Airline ID\n",
    "        thisLine.append(int(row[3])) # Source Airport ID\n",
    "        thisLine.append(int(row[5])) # Destination Airport ID\n",
    "        thisLine.append(int(row[7])) # Number of stops\n",
    "        thisLine.append(row[8]) # Plane type        \n",
    "        \n",
    "    except :\n",
    "        errors += 1\n",
    "        \n",
    "    else:\n",
    "        routes.append(thisLine)\n",
    "        \n",
    "print(\"Loaded\", len(routes), \"routes. Encountered\", errors, \"errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data as a Graph  \n",
    "\n",
    "We will use the [networkX](http://networkx.github.io/) library to represent the dataset as a graph. We will represent each airport with a node in the graph. For each route connecting two airports, we will use an edge connecting the corresponding nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Nodes\n",
    "\n",
    "We will use the ID of the airport as the main identifier of the node in the Directed Graph.\n",
    "\n",
    "[networkX](http://networkx.github.io/) allows us to attach labels to each node and edge of the Graph. We will use this feature to store the information provided by the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in airports:\n",
    "    G.add_node(row[0], id=row[0], \n",
    "               name=row[1], city=row[2], country=row[3],\n",
    "               iata=row[4], icao=row[5],\n",
    "               lat=row[6], long=row[7], alt=row[8],\n",
    "               utc_offset=row[9], daylight=row[10], timezone=row[11],\n",
    "               type=row[12], source=row[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Edges\n",
    "\n",
    "In a similar way we insert the edges in the Directed Graph.\n",
    "\n",
    "Due to some errors occured while loading the airport dataset, some airports are missing. When we use the _add__edge_ method, if the nodes do not exist, they will be created at that point. These automatically created nodes will not have any labels attached. This may create some problems later on. So we will exclude all routes that involve an airport that is not loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"routes.dat\")\n",
    "for row in routes:    \n",
    "    if row[2] in G.nodes() and row[3] in G.nodes():\n",
    "        G.add_edge(row[2], row[3], \n",
    "                   airline=row[0], airlineID=row[1],\n",
    "                  stops=row[4], aircraft=[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Nodes and Edges\n",
    "\n",
    "Retrieving a node is done very easily based on the hashable value provided (in our case, the ID of the airport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt': 13.0,\n",
       " 'city': 'Rome',\n",
       " 'country': 'Italy',\n",
       " 'daylight': 'E',\n",
       " 'iata': 'FCO',\n",
       " 'icao': 'LIRF',\n",
       " 'id': 1555,\n",
       " 'lat': 41.8002778,\n",
       " 'long': 12.2388889,\n",
       " 'name': 'Leonardo da Vinci–Fiumicino Airport',\n",
       " 'source': 'OurAirports',\n",
       " 'timezone': 'Europe/Rome',\n",
       " 'type': 'airport',\n",
       " 'utc_offset': 1.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.node[1555]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we can retrieve an edge by providing the ID of the source and destination node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aircraft': [5], 'airline': 'AZ', 'airlineID': 596, 'stops': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edge[1555][1550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aircraft': [5], 'airline': 'AZ', 'airlineID': 596, 'stops': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edge[1550][1555]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Properties\n",
    "\n",
    "[networkX](http://networkx.github.io/) provides algorithms for computing various metrics of the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 6874\\nNumber of edges: 36116\\nAverage in degree:   5.2540\\nAverage out degree:   5.2540'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c90ae163ebda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_node_connectivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/networkx/algorithms/connectivity/connectivity.py\u001b[0m in \u001b[0;36maverage_node_connectivity\u001b[0;34m(G, flow_func)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mnum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlocal_node_connectivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mden\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/networkx/algorithms/connectivity/connectivity.py\u001b[0m in \u001b[0;36mlocal_node_connectivity\u001b[0;34m(G, s, t, flow_func, auxiliary, residual, cutoff)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cutoff'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum_flow_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%sB'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%sA'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/networkx/algorithms/flow/maxflow.py\u001b[0m in \u001b[0;36mmaximum_flow_value\u001b[0;34m(G, s, t, capacity, flow_func, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetworkXError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flow_func has to be callable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapacity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapacity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flow_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/networkx/algorithms/flow/edmondskarp.py\u001b[0m in \u001b[0;36medmonds_karp\u001b[0;34m(G, s, t, capacity, residual, value_only, cutoff)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medmonds_karp_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapacity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'algorithm'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'edmonds_karp'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/networkx/algorithms/flow/edmondskarp.py\u001b[0m in \u001b[0;36medmonds_karp_impl\u001b[0;34m(G, s, t, capacity, residual, cutoff)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# Initialize/reset the residual network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flow'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \"\"\"\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nx.average_node_connectivity(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
