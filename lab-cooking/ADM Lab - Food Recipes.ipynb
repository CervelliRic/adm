{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More often than not data published on the web are not available in a structured dataset such as those we used in the other labs. Retrieving data requires going through the web pages, examine the [HTML]() code and extract the information. This technique is also known as [Web Scraping](https://en.wikipedia.org/wiki/Web_scraping). Clearly it can be extremely tedious.\n",
    "\n",
    "We will work with the Python module [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) that provides a nice set of tools for extracting information from web pages. The information that we will extract is located in the [BBC Food Recipes database](https://www.bbc.co.uk/food/recipes). We wish to retrieve the Food Recipes available and store them into a document database where each recipe becomes a separate document. We will use the [MongoDB](https://www.mongodb.com/what-is-mongodb) and the Database-as-a-service provider [mLab](https://mlab.com/).\n",
    "\n",
    "The first important step before diving into the code is to use your browser to inspect the HTML code of the pages that we will scap. All major browsers offer developer tools that present the HTML code in a human readable format. For example [Mozila Firefox Developer Tools](https://developer.mozilla.org/en-US/docs/Tools/Page_Inspector/How_to/Examine_and_edit_HTML). We will work with the following pages:\n",
    "* [Ingredients Index from A to Z](http://www.bbc.co.uk/food/ingredients)\n",
    "* [List of Ingredients](http://www.bbc.co.uk/food/ingredients/by/letter/a)\n",
    "* [List of Recipes for a specific Ingredient](http://www.bbc.co.uk/food/acidulated_water)\n",
    "* [Recipe](https://www.bbc.co.uk/food/recipes/roman-style_saltimbocca_44940)\n",
    "\n",
    "For each recipe we wish to extract and store as a document the following information:\n",
    "* Name\n",
    "* URL to BBC web site\n",
    "* Preparation Time\n",
    "* Cooking Time\n",
    "* Servings\n",
    "* List of Ingredients\n",
    "* Related Recipes\n",
    "\n",
    "## Scaping data\n",
    "\n",
    "We will start with the first page in order to retrieve the list of ingredients for a specific ingredient index letter. We start with the [List of Ingredients for Letter A](http://www.bbc.co.uk/food/ingredients/by/letter/a). \n",
    "\n",
    "If you inspect the HTML code of the page (via your browser) you will identify an [HTML order list tag](https://www.w3schools.com/tags/tag_ol.asp) containing one [HTML list item tag](https://www.w3schools.com/tags/tag_li.asp) for each ingredient. The URL of the page of ingredient is included in an [HTML link tag](https://www.w3schools.com/tags/tag_a.asp). Here is a short extract:\n",
    "\n",
    "```html\n",
    "<ol class=\"resources foods grid-view\">\n",
    "                <li class=\"resource food\" id=\"ackee\">\n",
    "                    <a href=\"/food/ackee\">\n",
    "                        <img src=\"http://ichef.bbci.co.uk/food/ic/food_16x9_111/foods/fruit_and_vegetables_16x9.jpg\" alt=\"ackee\" width=\"111\" height=\"63\">\n",
    "                        Ackee                    </a>\n",
    "                                    </li>\n",
    "  ....                                    \n",
    "                                    </ol>\n",
    "```\n",
    "\n",
    "The above information can be easily extracted from the web site using the [find all](http://www.pythonforbeginners.com/beautifulsoup/beautifulsoup-4-python) method of BeautifulSoup.\n",
    "\n",
    "We first start by retrieving the contents of the page http://www.bbc.co.uk/food/ingredients/by/letter/a using [requests](http://docs.python-requests.org/en/master/#) python library for using the HTTP protocol in a simple and straight-forward way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://www.bbc.co.uk/food/ingredients/by/letter/a'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to pass the contents of the HTTP response to BeautifulSoup so that the contents are parsed and converted into a python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to search the processed HTML page using the *find_all* method. We are looking for those ```<a>``` tags that contain the address of each individual ingredient. This will list all the links contained in the page, which are much more than those that we look for. So we will narrow down the search by looking into those that are of the form\n",
    "```/food/```. We do this by inspecting the *href* attribute of the ```<a>``` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/food/\n",
      "/food/\n",
      "/food/\n",
      "/food/recipes/\n",
      "/food/seasons\n",
      "/food/occasions\n",
      "/food/cuisines\n",
      "/food/dishes\n",
      "/food/chefs\n",
      "/food/programmes\n",
      "/food/ingredients\n",
      "/food/techniques\n",
      "/food/about\n",
      "/food/my/favourites\n",
      "/food/ingredients\n",
      "/food/ingredients/by/letter/b\n",
      "/food/ingredients/by/letter/c\n",
      "/food/ingredients/by/letter/d\n",
      "/food/ingredients/by/letter/e\n",
      "/food/ingredients/by/letter/f\n",
      "/food/ingredients/by/letter/g\n",
      "/food/ingredients/by/letter/h\n",
      "/food/ingredients/by/letter/i\n",
      "/food/ingredients/by/letter/j\n",
      "/food/ingredients/by/letter/k\n",
      "/food/ingredients/by/letter/l\n",
      "/food/ingredients/by/letter/m\n",
      "/food/ingredients/by/letter/n\n",
      "/food/ingredients/by/letter/o\n",
      "/food/ingredients/by/letter/p\n",
      "/food/ingredients/by/letter/q\n",
      "/food/ingredients/by/letter/r\n",
      "/food/ingredients/by/letter/s\n",
      "/food/ingredients/by/letter/t\n",
      "/food/ingredients/by/letter/u\n",
      "/food/ingredients/by/letter/v\n",
      "/food/ingredients/by/letter/w\n",
      "/food/ingredients/by/letter/y\n",
      "/food/ingredients/by/letter/z\n",
      "/food/acidulated_water\n",
      "/food/ackee\n",
      "/food/acorn_squash\n",
      "/food/aduki_beans\n",
      "/food/egg_liqueur\n",
      "/food/agar-agar\n",
      "/food/ale\n",
      "/food/aleppo_pepper\n",
      "/food/alfalfa_sprouts\n",
      "/food/allspice\n",
      "/food/almond\n",
      "/food/almond#related-foods\n",
      "/food/almond_essence\n",
      "/food/almond_extract\n",
      "/food/almond_milk\n",
      "/food/amaranth\n",
      "/food/amaretti\n",
      "/food/anchovy\n",
      "/food/anchovy#related-foods\n",
      "/food/anchovy_essence\n",
      "/food/angelica\n",
      "/food/bitters\n",
      "/food/anise\n",
      "/food/apple\n",
      "/food/apple#related-foods\n",
      "/food/apple_chutney\n",
      "/food/apple_juice\n",
      "/food/apple_sauce\n",
      "/food/apricot\n",
      "/food/apricot#related-foods\n",
      "/food/apricot_jam\n",
      "/food/arborio_rice\n",
      "/food/arborio_rice#related-foods\n",
      "/food/arbroath_smokie\n",
      "/food/argan_oil\n",
      "/food/arrowroot\n",
      "/food/artichoke\n",
      "/food/artichoke#related-foods\n",
      "/food/asafoetida\n",
      "/food/asparagus\n",
      "/food/aubergine\n",
      "/food/aubergine#related-foods\n",
      "/food/avocado\n",
      "/food/avocado#related-foods\n",
      "/food/ingredients\n",
      "/food/ingredients/by/letter/b\n",
      "/food/ingredients/by/letter/c\n",
      "/food/ingredients/by/letter/d\n",
      "/food/ingredients/by/letter/e\n",
      "/food/ingredients/by/letter/f\n",
      "/food/ingredients/by/letter/g\n",
      "/food/ingredients/by/letter/h\n",
      "/food/ingredients/by/letter/i\n",
      "/food/ingredients/by/letter/j\n",
      "/food/ingredients/by/letter/k\n",
      "/food/ingredients/by/letter/l\n",
      "/food/ingredients/by/letter/m\n",
      "/food/ingredients/by/letter/n\n",
      "/food/ingredients/by/letter/o\n",
      "/food/ingredients/by/letter/p\n",
      "/food/ingredients/by/letter/q\n",
      "/food/ingredients/by/letter/r\n",
      "/food/ingredients/by/letter/s\n",
      "/food/ingredients/by/letter/t\n",
      "/food/ingredients/by/letter/u\n",
      "/food/ingredients/by/letter/v\n",
      "/food/ingredients/by/letter/w\n",
      "/food/ingredients/by/letter/y\n",
      "/food/ingredients/by/letter/z\n",
      "/food/\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    if (link.get('href').startswith('/food/')):\n",
    "        print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
