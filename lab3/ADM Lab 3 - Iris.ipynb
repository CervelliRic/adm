{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3rd lab material is based on the Refcard from [DZone](https://dzone.com/) on [Practical Data Mining with Python](https://dzone.com/refcardz/data-mining-discovering-and).\n",
    "\n",
    "We start using the [Iris Dataset](http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) that includes measurements on 150 [iris plants](https://en.wikipedia.org/wiki/Iris_%28plant%29). Each measurement includes:\n",
    "* Sepal Length, \n",
    "* Sepal Width, \n",
    "* Petal Length and \n",
    "* Petal Width\n",
    "\n",
    "The 150 irises plants consists of 3 different types: Setosa, Versicolour, and Virginica. The type of the plant is also included in the dataset. We can therefore use this as a reference and compare the results of the Clustering algorithm with the actual values. Look [here](https://en.wikipedia.org/wiki/Iris_flower_data_set) for more information about the dataset.\n",
    "\n",
    "We start by retrieving the dataset directly from the web using [urllib](https://docs.python.org/3/library/urllib.html) method from the standard python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = 'http://aima.cs.berkeley.edu/data/iris.csv'\n",
    "u = urllib.request.urlopen(url)\n",
    "iris = u.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to store the information retrieved to a local file so that we can work with the data without the need to re-download again and again. \n",
    "\n",
    "So now we work a bit more with files, this time we will create a new file and _write_ data in the file. For a nice introduction to using files in python and how to read & write files, you can follow the [Introduction to Data Processing with Python](http://opentechschool.github.io/python-data-intro/core/text-files.html).\n",
    "\n",
    "Notice that the _open_ method has a second parameter \"wb\" - \"w\" stands for _write_ and \"b\" stands for _binary_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "localFile = open(\"iris.csv\", \"wb\")\n",
    "localFile.write(iris)\n",
    "localFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file retrieved follows a comma-separated format. \n",
    "\n",
    "In the 2nd lab we worked with CSV files using the [CSVREADER](https://docs.python.org/2/library/csv.html) a standard python package as explained in [Reading and writing comma-separated data](http://opentechschool.github.io/python-data-intro/core/csv.html). \n",
    "\n",
    "Although this is a very nice and simple way to access data, in this lab we will work with [NUMPY](http://www.numpy.org/) a python library for scientific computing and in particular [GENFROMTXT](http://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html). The main benefit is that it offers many options in terms of customizing the way the data are loaded from the text file, with missing values handled as specified.\n",
    "\n",
    "Notice that the _genfromtxt_ method lets us define the delimiter (so we can handle files where values are separated with other characters, not just a comma), and also we can define which columns we wish to import.\n",
    "\n",
    "In our case, we import the 4 measurements into the _data_ array and the name of the category in the _target_ array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt, zeros\n",
    "\n",
    "# read the first 4 columns\n",
    "data = genfromtxt('iris.csv',delimiter=',',usecols=(0,1,2,3)) \n",
    "\n",
    "# read the fifth column\n",
    "target = genfromtxt('iris.csv',delimiter=',',usecols=(4),dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values produced by processing the text file are converted into an [numpy.ndarray](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html). This data type represents a multidimensional, homogeneous array of fixed-size items. An associated data-type object describes the format of each element in the array (its byte-order, how many bytes it occupies in memory, whether it is an integer, a floating point number, or something else, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can process the elements of the array and create a set of unique values. Python let's us do this very easily by using the [set](https://docs.python.org/2/library/sets.html) method. Essentially the _set_ method constructs an unordered collection of unique elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(set(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an understanding of the dataset and the different values, we visualize the dataset using the [matplotlib](http://matplotlib.org/). We will use the [pyplot](http://matplotlib.org/api/pyplot_api.html) module that combines pyplot with numpy into a single namespace to provides a MATLAB-like plotting framework.\n",
    "\n",
    "The following plot uses the blue color for the Setosa category, the red for the Versicolor and the green for the Virginica. This is the third argument of the _plot_ method as \"bo\", \"ro\" and \"go\". The \"o\" added to each line stands for circle markers. \n",
    "\n",
    "Homework:\n",
    "* Try different marker shapes by replacing the \"o\" with \"+\", \"v\", \"x\" ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import plot, show\n",
    "plot(data[target=='setosa',0],data[target=='setosa',2],'bo')\n",
    "plot(data[target=='versicolor',0],data[target=='versicolor',2],'ro')\n",
    "plot(data[target=='virginica',0],data[target=='virginica',2],'go')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example notice how we filter the elements of the numpy.ndarray in each line. We use the [boolean indexing](http://docs.scipy.org/doc/numpy/user/basics.indexing.html#boolean-or-mask-index-arrays) feature of numpy.\n",
    "\n",
    "This particular piece of code can be decomposed into two steps. The _target=='setosa'_ creates a binary array with the same shape as the _target_ array where each row _x_ is replaced by a boolean value that correspond to the result of the operation _x == 'setosa'_. \n",
    "\n",
    "The second step is doing the filtering of the original data ndarray based on the boolean array produced in the first step. Sot the _data[ ... , 0]_ will produce a 1-D array containing all the elements in the indexed array corresponding to all the true elements in the boolean array. \n",
    "\n",
    "Homework:\n",
    "* Produce plots for the other measurements: Sepal Length vs Sepal Width, Sepal Length vs Petal Width, Sepal Width vs Petal Length, Petal Length vs Petal Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import figure, subplot, hist, xlim, show\n",
    "xmin = min(data[:,0])\n",
    "xmax = max(data[:,0])\n",
    "figure()\n",
    "subplot(411) # distribution of the setosa class (1st, on the top)\n",
    "hist(data[target=='setosa',0],color='b',alpha=.2)\n",
    "xlim(xmin,xmax)\n",
    "subplot(412) # distribution of the versicolor class (2nd)\n",
    "hist(data[target=='versicolor',0],color='r',alpha=.2)\n",
    "xlim(xmin,xmax)\n",
    "subplot(413) # distribution of the virginica class (3rd)\n",
    "hist(data[target=='virginica',0],color='g',alpha=.2)\n",
    "xlim(xmin,xmax)\n",
    "subplot(414) # global histogram (4th, on the bottom)\n",
    "hist(data[:,0],color='y',alpha=.7)\n",
    "xlim(xmin,xmax)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "kmeans = KMeans(n_clusters=3, init='random') # initialization\n",
    "kmeans.fit(data) # actual execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = kmeans.predict(data)\n",
    "print(c.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure()\n",
    "subplot(211) # top figure with the real classes\n",
    "plot(data[target=='setosa',0],data[target=='setosa',2],'bo')\n",
    "plot(data[target=='versicolor',0],data[target=='versicolor',2],'ro')\n",
    "plot(data[target=='virginica',0],data[target=='virginica',2],'go')\n",
    "subplot(212) # bottom figure with classes assigned automatically\n",
    "plot(data[c==1,0],data[c==1,2],'bo',alpha=.7)\n",
    "plot(data[c==2,0],data[c==2,2],'go',alpha=.7)\n",
    "plot(data[c==0,0],data[c==0,2],'mo',alpha=.7)\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
